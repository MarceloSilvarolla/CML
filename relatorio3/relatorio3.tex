\documentclass[12pt]{article}
%\usepackage[margin=1in]{geometry}% Change the margins here if you wish.
%\setlength{\parindent}{0pt} % This is the set the indent length for new paragraphs, change if you want. 
%\setlength{\parskip}{5pt} % This sets the distance between paragraphs, which will be used anytime you have a blank line in your LaTeX code.
%\pagenumbering{gobble}% This means the page will not be numbered. You can comment it out if you like page numbers.

%------------------------------------

\usepackage{color}
\usepackage[utf8]{inputenc}
\usepackage{hyperref}
\usepackage{listings}% http://ctan.org/pkg/listings

\usepackage[margin=1in]{geometry}
\usepackage{cprotect}
\usepackage{mathtools}
\usepackage{fancyvrb}

\usepackage{comment}
\linespread{1.6}
\usepackage{examplep}

\renewcommand{\refname}{Referências}

% These packages allow the most of the common "mathly things"
\usepackage{amsmath,amsthm,amssymb}

% This package allows you to add images.
\usepackage{graphicx}
\usepackage{float}

\usepackage{listings}
\usepackage{upquote,textcomp}

\newcommand{\grn}{\textcolor{green}}
\newcommand{\red}{\textcolor{red}}
\newcommand\todo[1]{\red{\Large \text{TODO: #1}}}
\newcommand{\defeq}{\vcentcolon=}
\newcommand{\eqdef}{=\vcentcolon}
\newcommand\Item[1][]{%
  \ifx\relax#1\relax  \item \else \item[#1] \fi
  \abovedisplayskip=0pt\abovedisplayshortskip=0pt~\vspace*{-\baselineskip}}
\newcommand\eb[1]{[[\texttt{#1}]]}
% Should you need any additional packages, you can load them here. If you've looked up something (like on DeTeXify), it should specify if you need a special package.  Just copy and paste what is below, and put the package name in the { }.  
\usepackage{wasysym} %this lets me make smiley faces :-)

\title{CML - Uma Linguagem para {\it Machine Learning} \\ \Large Relatório 3 - Trabalho de Conceitos de Linguagem de Programação}

\author{Caio Lopes, Leonardo Blanger, Marcelo Silvarolla}

\date{20 de junho de 2018}

\begin{document}
\lstset{
  basicstyle=\ttfamily,
  columns=fullflexible,
  keepspaces=true,
  mathescape
}

\maketitle
\tableofcontents
\newpage
\section{Estrutura Geral do Projeto}

No diretório \texttt{demonstracao} encontram-se arquivos usados nos exemplos descritos na seção \ref{Exemplos}. Os relatórios 1 e 2 modificados estão nos diretórios \texttt{relatorio1} e \texttt{relatorio2}, enquanto que este relatório está no diretório \texttt{relatorio3}.

O diretório \texttt{Interpretador} é o principal do projeto. Contém

\begin{enumerate}
	\item arquivos com extensão ".cml", que são exemplos para teste, conforme descrito na seção \ref{Exemplos}
	\item arquivos com extensão ".csv" e ".model", usados/criados pelos exemplos de teste
	\item um \textit{script} chamado \texttt{cml} para facilitar o uso do interpretador, conforme descrito no Manual (seção \ref{Man})
	\item \texttt{CML.cm}, responsável pela compilação do nosso código
	\item \texttt{CML.lex}, o analisador léxico
	\item \texttt{CML.yacc}, o analisador sintático
	\item \texttt{datatypes.sml}, o qual especifica a estrutura das \textit{parse trees} abstratas.
	\item \texttt{glue.sml}, arquivo para integração de Lex com Yacc.
	\item \texttt{interpreter.sml}, que realiza as tarefas principais da interpretação. Este arquivo contém a função \texttt{interpret}, que é responsável por obter a árvore sintática do código fornecido, realizar a verificação de tipos, e se não ocorrer nenhum erro nestas etapas, executar o código.
	\item \texttt{Aux/auxiliary.sml}, arquivo de funções auxiliares para interpretação, que contém as seguintes estruturas:
\begin{itemize}
\item \texttt{Location}: Define o  \texttt{type location}, que representa posições da \textit{store}, onde os dados ficam armazenados.

\item \texttt{ArrayValue}: Define o \texttt{type arrayValue}, que representa os arrays na linguagem. Arrays em CML são implementados como listas de \textit{locations}, onde cada location aramazena o valor de um elemento do array (que pode ser outro array, no caso de arrays de mais de uma dimensão).

\item \texttt{ExpressibleValue}: Representa o conjunto de tipos que são aceitos como resultado de uma expressão. Define o \texttt{datatype expressibleValue}, que pode ser \texttt{Int}, \texttt{Real}, \texttt{Bool}, \texttt{Char}, \texttt{String}, \texttt{Dataset}, \texttt{Model}, \texttt{ArrayValue}, ou \texttt{VoidValue}. Este último representa o tipo do retorno de funções \texttt{void}, não sendo usado para atribuições de variáveis.

\item \texttt{StorableValue}: Define o \texttt{datatype storableValue}, que representa os tipos que podem ser armazenados na \textit{store}, e pode assumir os mesmos tipos presentes no \texttt{expressibleValue}, com exceção de \texttt{VoidValue}, além dos tipos \texttt{Unused}, que representa uma localização que não foi associada a nenhuma variável, e \texttt{Undefined}, que representa uma localização que foi associada a uma variável que ainda não recebeu nenhuma atribuição.

\item \texttt{Store}: Contém os dados que estão sendo armazendas durante a execução de um programa em CML. É responsável por fornecer funções de alocação e desalocação de localizações, além de atualização e acesso a valores armazenados na \textit{store}.

\item \texttt{Function}: Define o tipo \texttt{function}, responsável por representar uma função de CML. Funções de CML são representadas em SML através de uma outra função, que recebe uma lista de localizações e uma instância da \textit{store}, onde estas localizações armazenam os valores que a função deve receber como parâmetro, e devolve um \texttt{ExpressibleValue}.

\item \texttt{DenotableValue}: Define o tipo \texttt{denotableValue}, responsável por representar aquilo que pode ser associado com um identificador da linguagem. Pode ser do tipo \texttt{Location}, que significa uma posição da \textit{store} onde algum  \textit{ExpressibleValue} está armazenado, \texttt{Function}, que representa uma função em CML, ou \texttt{Unbound}, que é associado a qualquer identificador que não tenha sido declarado como uma variável ou definido com uma função na linguagem.

\item \texttt{ReturnFlag}: Define o tipo \texttt{returnFlag}, que simplesmente assume um valor booleano, responsável por representar a ocorrência de um comando \texttt{return}.

\item \texttt{LearningAuxBridge}: Responsável por traduzir as chamadas de funções predefinidas para chamadas das funções da biblioteca de Aprendizado de Máquina. Assim como as funções que são definidas em CML, as funções predefinidas também recebem uma lista de localizações e uma \textit{store} contendo os valores dos parâmetros. Esta estrutura é responsável por obter os valores destes parâmetros da \textit{store} e invocar as respectivas funções na biblioteca de Aprendizado de Máquina.

\item \texttt{Print}: Responsável por definir as funções de escrita em CML, \texttt{print} e \texttt{println}. Estas funções não estavam previstas em fases anteriores, mas implementamos para facilitar a depuração, tanto de códigos em CML, quanto do próprio interpretador.
 
\item \texttt{Env}: Responsável por definir o \textit{environment}, que pode ser interpretado como uma função que mapeia cada identificador da linguagem para um \texttt{DenotableValue}. Nomes de variáveis são mapeados para \texttt{Locations}, nomes de funções são mapeados para \texttt{Functions}, e identificadores não declarados são mapeados para \texttt{Unbound}. Fornece funções para associar identificadores com \texttt{DenotableValues} e acessar \texttt{DenotableValues} associados com identificadores.

\item \texttt{Sort}: Usada para a checagem de tipos, esta estrutura define o \texttt{datatype sort} e funções auxiliares básicas que o usam. Mais especificamente, os valores de tipo (em SML) \texttt{sort} representam um tipo de CML, podendo ser \texttt{Int, Real, Char, Bool, String, Dataset, Model, Array, Void, Unbound, Any, Product} ou \texttt{To}. O tipo especial \texttt{Any} serve de substituto a um tipo desconhecido da linguagem. Por exemplo, ao fazermos a checagem da expressão \texttt{\{\}} em

\begin{Verbatim}
int[] v = {};
\end{Verbatim}

não sabemos se o array vazio é um array de inteiros, reais, strings, etc., então o tipificamos como Array de Any.

Adicionamos \texttt{Product} e \texttt{To} para representar tipos produto e mapeamentos, respectivamente. Por exemplo, no código

\begin{Verbatim}
dataset f(int x, real y);
\end{Verbatim}

\texttt{f} recebe o tipo \texttt{To (Product [Int, Real], Dataset) }.

A função mais importante de \texttt{Sort} é a \texttt{commonSort}, que extrai o tipo mais específico entre dois tipos. Por exemplo, dentre \texttt{Array Any} e \texttt{Array Int}, o segundo é mais específico.

\item \texttt{LocalTypeEnv}: Define o \textit{environment} de tipos local, que contém os tipos de todas as variáveis declaradas no escopo atual. É utilizada para detectar declarações múltiplas de uma mesma variável no mesmo bloco.

\item \texttt{GlobalTypeEnv}: Define o \textit{environment} de tipos global, que contém os tipos de todas as variáveis declaradas. É utilizada para a verificação de tipos, por exemplo em \texttt{x = 42;}, quando se verifica que o tipo de \texttt{x} é, de fato, \texttt{int}.
\end{itemize}
\item \texttt{LearningLib}, diretório que contém a biblioteca de Aprendizado de Máquina utilizada pela linguagem. Esta biblioteca implementa todas as funções predefinidas relacionadas com modelos de aprendizado e manipulação de conjuntos de dados. A interface é exportada pelo arquivo \texttt{learning.sml}, e a compilação é feita por \texttt{LearningLib.cm}. Ele contém os seguintes subdiretórios:

\begin{itemize} \item \texttt{dataset}, diretório que contém a implementação das funções utilizadas para ler, salvar, e manipular conjuntos de dados. São elas \texttt{columns}, \texttt{remove\_columns}, \texttt{rows}, \texttt{num\_rows}, \texttt{load\_data}, e \texttt{save\_data}. Este diretório contém também a implementação de diversas funções utilizadas internamente pela biblioteca de aprendizado.

\item \texttt{models}, o qual contém a implementação dos modelos de aprendizado: \textit{Perceptron}, \textit{Pocket-Perceptron}, \textit{Regressão Linear} e \textit{Regressão Logística}. Para cada um deles, foram implementadas funções para treinamento e predição, além de leitura e gravação em arquivo dos parâmetros e outras informações necessárias para a reconstrução destes modelos. Neste diretório também foram implementadas funcionalidades para pré-processamento e formatação dos conjuntos de dados, de forma a satisfazer requisitos de entrada para os algoritmos de treinamento. Estas funcionalidades estão implementadas no arquivo \texttt{preprocesss\_dataset.sml}. Como exemplos destas funcionalidades, é necessário normalizar os valores de atributos numéricos dos conjuntos de dados utilizando a média e o desvio padrão destes atributos, além disso, atributos categóricos precisam ser codificados como vetores \textit{one-hot}.

\item \texttt{testesDeMachineLearning}, que contém testes para a biblioteca de Machine Learning independentes do interpretador. Estes testes podem ser ignorados para fins de correção.
\end{itemize}

\item Makefile, para que se possa dar "make clean" e limpar os arquivos gerados pelo Compilation Manager. É usado pelo \textit{script} cml.
\end{enumerate}



\section{Manual de Uso}\label{Man}

Criamos um script que facilita o uso do interpretador CML. Dentro do diretório \texttt{Interpretador}, execute o seguinte comando, substituindo onde indicado pelo caminho do fonte CML a ser interpretado:

\begin{verbatim}
./cml <CAMINHO PARA O FONTE>
\end{verbatim}

Este script apaga os arquivos temporários gerados por execuções anteriores do interpretador, recompila o interpretador, e invoca a interpretação do arquivo fornecido.

É possível também compilar e invocar o interpretador manualmente. Dentro do diretório \texttt{Interpretador}, utilize o comando \texttt{sml} para abrir um console SML, e execute os seguinte comando neste console:

\begin{verbatim}
CM.make "CML.cm";
\end{verbatim}

Isto irá compilar os módulos necessários do interpretador. Ainda dentro do console SML, execute:

\begin{verbatim}
CML.interpret "<CAMINHO PARA O FONTE>";
\end{verbatim}

Isto irá invocar a função de interpretação de CML, com o arquivo informado como entrada. Esta função monta a árvore sintática, realiza a verificação de tipos, e interpreta o código.

É possível visualizar a árvore sintática do código invocando a seguinte função:

\begin{verbatim}
CML.parse "<CAMINHO PARA O FONTE>"
\end{verbatim}

\section{Exemplos}\label{Exemplos}

Nesta seção apresentaremos um conjunto de exemplos de uso da linguagem, com o objetivo de demonstrar o funcionamento das funcionalidades gerais da linguagem e dos algoritmos de Machine Learning.

\subsection{Exemplos de Uso da Linguagem}

De modo a demonstrar as funcionalidades básicas da linguagem, preparamos um conjunto de exemplos corretos e incorretos. Os exemplos corretos permitem observar o uso correto da linguagem, e foram planejados de forma a executar sem erros. Os exemplos incorretos permitem observar a capacidade do interpretador em identificar erros de sintaxe nos códigos. O interpretador deve ser capaz de informar o erro no momento da execução destes exemplos.

Estes exemplos estão no diretório \texttt{Interpretador}, sendo que os exemplos corretos e incorretos estão em arquivos identificados com os prefixos \texttt{good} e \texttt{bad} (por exemplo,\\ \texttt{Interpretador/good2.cml} ou \texttt{Interpretador/bad1.cml}).

\subsection{Classificação usando Perceptron}
O arquivo \texttt{Interpretador/classification1.cml} contém um exemplo do treinamento de um classificador do tipo Perceptron. O exemplo utiliza o conjunto de dados da planilha \texttt{demonstracao/classification1.csv}, composto por 180 linhas, cada uma com os atributos \texttt{x1}, \texttt{x2}, e \texttt{y}. Os dois primeiros atributos assumem valores reais e correspondem a posição de cada exemplo no plano, enquanto o terceiro pode assumir 1.0 ou -1.0.

O objetivo será treinar um Perceptron capaz de classificar os pontos dentre positivos ou negativos, com base nos valores dos atributos \texttt{x1} e \texttt{x2}.

O exemplo treina o classificador na linha:

\begin{verbatim}
model P = perceptron(X, y, 1000);
\end{verbatim}

Nesta função, \texttt{X} e \texttt{y} correspondem aos \textit{datasets} contendo as entradas e as saídas, respectivamente, enquanto o terceiro parâmetro corresponde a quantidade de iterações de treinamento a serem executadas.

Para executar o arquivo, de dentro do diretório \texttt{Interpretador}, execute

\begin{verbatim}
./cml classification1.cml
\end{verbatim}

Este código treina o Perceptron e salva o modelo treinado no arquivo \texttt{Interpretador/P.model}. Em seguida ele usa o modelo treinado para predizer a categoria dos dados, e salva estas predições como uma nova planilha \texttt{demonstracao/classification1\_output.csv}.

Como CML não possui funcionalidades para visualização dos dados, incluímos um conjunto de scripts em Python no diretório \texttt{demonstracao}, capazes de plotar os dados das planilhas originais e as predições. Para visualizar a predição do Perceptron, dentro de \texttt{demonstracao} execute:

\begin{verbatim}
python visualize_classification1.py classification1_output.csv
\end{verbatim}

Este script gera dois plots. O primeiro deles corresponde os dados originais, sem categorias, enquanto o segundo corresponde aos mesmos dados, porém coloridos de acordo com a categoria (positivo ou negativo) predita pelo classificador.

\subsection{Classificação usando Pocket-Perceptron}

O arquivo \texttt{Interpretador/classification2.cml} contém um exemplo de treinamento de um classificador do tipo Pocket-Perceptron. Este é um modelo de aprendizado similar ao Perceptron, porém capaz de lidar com dados não linearmente separáveis. Ele é menos eficiente para ser treinado, mas a velocidade de predição é a mesma do Perceptron.

O exemplo utiliza um conjunto de dados armazenado na planilha\\ \texttt{demonstracao/classification2.csv}. Este conjunto de dados é composto por 1800 exemplos, cada um deles com três atributos: \texttt{x1}, \texttt{x2}, que novamente representam a posição de um ponto no plano, e \texttt{color}, que representa a cor associada com o exemplo, que pode assumir as categorias \texttt{blue} ou \texttt{green}. O objetivo, novamente, é treinar um classificador capaz de classificar os pontos dentre azuis e verdes, com base nas coordenadas do ponto no plano. 

Para executar este código, dentro da pasta \texttt{Interpretador}, execute:

\begin{verbatim}
./cml classification2.cml
\end{verbatim}

Este código treina o Pocket-Perceptron nos dados, e salva os dados do modelo no arquivo \texttt{Interpretador/PP.model}. Em seguida, ele usa o modelo treinado para realizar a predição das cores dos exemplos do conjunto de treinamento, e salva estas predições na planilha \texttt{demonstracao/classification2\_output.csv}.

Para visualizar estas predições, dentro do diretório \texttt{demonstracao}, execute:

\begin{verbatim}
python visualize_classification2.py classification2_output.csv
\end{verbatim}

Este script irá gerar dois plots, o primeiro deles corresponde aos dados de entrada, com as cores corretas. Note que, diferente dos dados do exemplo anterior, este conjunto de dados não é linearmente separável, ou seja, não é possível traçar um hiper-plano (reta, no caso de duas dimensões) que separe as duas categorias. O Pocket-Perceptron é uma variação do Perceptron normal capaz de lidar com este tipo de situação. Ele treina por uma quantidade limitada de iterações, e reporta a melhor separação linear que ele foi capaz de encontrar. O segundo plot corresponde aos dados de entrada com as cores atribuídas pelo classificador. É possível perceber que ele separa as duas categorias com uma reta da melhor forma possível, dada a quantidade de iterações executadas.

\subsection{Classificação usando Regressão Logística}

O arquivo \texttt{Interpretador/logistic\_regression.cml} contém um exemplo de treinamento de um classificador para Regressão Logística. Diferente do Perceptron, que produz uma categoria como saída, este tipo de modelo é utilizado para predizer probabilidades sobre categorias.

O exemplo utiliza os mesmos dados que o Pocket-Perceptron. Porém, o objetivo agora será estimar a probabilidade de cada ponto assumir a cor verde, com base nas suas coordenadas no plano.

O treinamento é realizado na linha:

\begin{verbatim}
model logR = logistic_regression(X, y, "green", 0.01, 10, 100);
\end{verbatim}

Nesta função, \texttt{X} e \texttt{y} correspondem aos datasets contendo as entradas e saídas de treinamento, respectivamente. \texttt{"green"} é a categoria da saída da qual gostaríamos de estimar a probabilidade. 0.01 é a taxa de aprendizado, que corresponde à velocidade em que os parâmetros do modelo são atualizados ao longo das iterações, quanto maior, mais rápido, porém mais instável é o treinamento. 10 é o tamanho do \textit{batch} de treinamento, ou seja, a quantidade de exemplos analisados a cada iteração. E 100 é a quantidade de iterações do treinamento.

A cada iteração, o algoritmo de treinamento busca ajustar os parâmetros do modelo de forma a minimizar a Entropia Cruzada Média, uma medida de erro bem comum em tarefas de aprendizado de máquina em que a saída represente uma probabilidade. O valor desta medida de erro é mostrado na tela a cada iteração.

Para executar o código deste exemplo, dentro do diretório \texttt{Interpretador}, execute:

\begin{verbatim}
./cml logistic_regression.cml
\end{verbatim}

Este código treina um classificador para Regressão Logística e salva os parâmetros deste classificador no arquivo \texttt{Interpretador/logR.model}. Em seguida utiliza o modelo treinado para estimar a probabilidade de cada ponto do conjunto de treinamento ser verde, e salva estas probabilidades na planilha \texttt{demonstracao/logistic\_output.csv}.

Para visualizar estas predições, dentro do diretório \texttt{demonstracao}, execute:

\begin{verbatim}
python visualize_logistic_regression.py logistic_output.csv
\end{verbatim}

Este script irá gerar dois plots. O primeiro deles corresponde aos dados originais com as respectivas cores, enquanto o segundo corresponde a um mapa de calor destes mesmos dados, onde o intervalo de cores corresponde ao intervalo $[0,1]$ atribuído pelo classificador. Observe que próximo aos pontos médios de cada cor, a probabilidade é bem intensa (bem alta ou bem baixa), pois o classificador tem um alto nível de certeza sobre a cor dos pontos nestas regiões, enquanto que no meio do caminho entre estes pontos médios, as probabilidades assumem valores intermediários, pois o classificador não tem muita certeza sobre a cor de pontos nesta região, atribuindo probabilidades próximas de 0.5.

\subsection{Regressão Linear}

O arquivo \texttt{Interpretador/linear\_regression.cml} contém um exemplo de treinamento de um modelo de Regressão Linear. Diferente dos modelos classificadores dos exemplos anteriores, que são treinados para produzirem categorias ou probabilidades sobre categorias como saída, um modelo de regressão linear pode produzir qualquer valor real.

O exemplo utiliza o conjunto de dados armazenado na planilha \\ \texttt{demonstracao/linear\_regression.csv}. Cada exemplo deste conjunto de dados representa um imóvel, através de seu tamanho em $m^2$, e seu preço. O objetivo será treinar um modelo capaz de estimar o valor de um imóvel com base no seu tamanho.

O treinamento é realizado na linha:

\begin{verbatim}
model linR = linear_regression(X, y, 0.01, 10, 1000);
\end{verbatim}

Nesta função, os parâmetros tem o mesmo significado da regressão logística, com a exceção de que agora, não é necessário informar a categoria, pois a saída será um valor contínuo.

A cada iteração, o algoritmo de treinamento busca ajustar os parâmetros do modelo de forma a minimizar o Erro Quadrado Médio, uma medida de erro bem comum em tarefas de aprendizado de máquina em que a saída seja um valor contínuo. O valor desta medida de erro é mostrado na tela a cada iteração.

Para executar o código deste exemplo, dentro do diretório \texttt{Interpretador}, execute:

\begin{verbatim}
./cml linear_regression.cml
\end{verbatim}

Este código treina um modelo de regressão linear e salva os parâmetros deste modelo no arquivo \texttt{Interpretador/linR.model}. Em seguida utiliza este modelo treinado para predizer o valor de cada imóvel, e salva estes valores na planilha \texttt{demonstracao/linear\_output.csv}.

Para visualizar estas predições, dentro do diretório \texttt{demonstracao}, execute:

\begin{verbatim}
python visualize_linear_regression.py linear_output.csv
\end{verbatim}

O primeiro plot mostra aos dados originais, onde o eixo horizontal corresponde ao tamanho, e o eixo vertical corresponde ao valor do imóvel. O segundo plot mostra a mesma informação do primeiro, juntamente com a reta que passa pelos pontos correspondentes aos preços estimados pelo modelo para cada valor de $m^2$ presente no conjunto.

\subsection{Um Exemplo mais Realista}

De forma a ilustrar várias funcionalidades da linguagem, preparamos um exemplo mais complexo de treinamento e uso de um modelo de aprendizado. Para este exemplo, utilizamos o conjunto de dados \textit{TMDB 5000 Movie Dataset}\footnote{Disponível na plataforma de competições de \textit{data science} Kaggle, em \url{www.kaggle.com/tmdb/tmdb-movie-metadata}}. Este conjunto de dados corresponde a entradas da base de dados do site TMDb\footnote{\url{www.themoviedb.org}}, uma plataforma que mantém dados sobre filmes, e permite que usuários votem na qualidade destes filmes. 

Este conjunto de dados contém 4803 exemplos, cada um deles com vários atributos, como elenco, gênero, orçamento, etc. Para este exemplo, removemos alguns destes atributos dos dados, que tornavam a tarefa muito mais complexa, mantendo apenas os atributos: orçamento, idioma original, lucro, duração, média dos votos do público, e quantidade de votos recebidos. O conjunto de dados modificado está na planilha \texttt{demonstracao/tmdb\_simple.csv}. 

Os votos do público assumem valores no intervalo de 0 a 10, e o objetivo deste exemplo será treinar um modelo de regressão capaz de estimar a média dos votos com base nos outros atributos. Como este é um exemplo mais elaborado, iremos seguir boas práticas para projetos de Aprendizado de Máquina e separar este conjunto de dados em um conjunto de treinamento, que será utilizado para o treinamento do modelo de regressão, da mesma forma que os exemplos anteriores, e um conjunto de testes, que será utilizado para avaliar a capacidade de generalizar a predição para dados inéditos. O código para este exemplo se encontra no arquivo \texttt{Interpretador/tmdb.cml}.

Este código explora diversas funcionalidades da linguagem CML.  Primeiramente, ele utiliza uma função para separar os dados em treinamento e teste, e esta função faz uso das funções predefinidas para manipulação de datasets \texttt{rows} e \texttt{num\_rows}. Basicamente, esta função está selecionado os \texttt{test\_size} primeiros elementos do dataset para compor o conjunto de testes, e selecionando os \texttt{train\_size} elementos seguintes para compor o conjunto de treinamento. Esta função retorna um array de datasets, contendo os conjuntos de treinamento e testes nas duas primeiras posições.

Em seguida este código salva os conjuntos de treinamento e testes em duas planilhas separadas, \texttt{demonstracao/tmdb\_train.csv}, e \texttt{demonstracao/tmdb\_test.csv}, para então treinar um modelo de regressão linear por 500 iterações sobre o conjunto de treinamento. Este treinamento pode demorar dependendo da máquina em que o código estiver sendo executado. Ao final do treinamento, este código salva as informações do modelo treinado no arquivo \texttt{Interpretador/tmdb\_linreg.model}. Para evitar a execução de todo o processo de treinamento, já incluímos no projeto os arquivos gerados pela execução deste código.

O arquivo \texttt{Interpretador/tmdb\_test.cml} usa este modelo treinado para predizer a média dos votos para os exemplos do conjunto de testes, que não foram utilizados para o treinamento do modelo. Em seguida este arquivo salva as predições no arquivo\\ \texttt{demonstracao/tmdb\_predictions.csv} e as médias corretas em \texttt{demonstracao/tmdb\_correct.csv}.

Incluímos um script que permite avaliar a qualidade da predição realizada. Dentro do diretório \texttt{demonstracao}, execute:

\begin{verbatim}
python tmdb_mean_absolute_error.py tmdb_correct.csv tmdb_predictions.csv
\end{verbatim}

Este script irá calcular o erro absoluto médio entre as predições e as médias de votos corretas para cada filme do conjunto de testes. Na nossa execução, este valor ficou em aproximadamente 0.8 (os votos são de 0 a 10). Lembre que estes dados não foram utilizados no processo de treinamento, indicando que o modelo adquiriu capacidade para generalizar o aprendizado para dados inéditos.

\section{Facilidades e Dificuldades Encontradas}
\subsection{Problema das passadas}
	 Cometemos um erro sutil na semântica denotacional, que impedia o funcionamento de funções mutuamente recursivas. Utilizamos a ideia das múltiplas passadas, $P1, P2, P3$, que iam redefinindo as funções para que enxergassem as demais. Por exemplo, considere o programa abaixo:
	
	\begin{verbatim}
	int main() {
	g(8); // 1337
	return 0;
	}
	
	int f(int x) {
	if(x == 0) { return 42; }
	return g(x - 1);
	}
	
	int g(int x) {
	if(x == 0) { return 1337; }
	return f(x - 1);
	}
	
	\end{verbatim}
	
	Na primeira passada, \texttt{g} conhece \texttt{f}, que não conhece \texttt{g}.
	Na segunda passada, \texttt{g} conhece a \texttt{f} da segunda passada, que, por sua vez, conhece a \texttt{g} da primeira passada. Portanto, ao fazermos a chamada a \texttt{g} no \texttt{main}, depois de um certo número de chamadas recursivas, chegamos numa chamada de \texttt{g} dentro da \texttt{f} da primeira passada, que não a conhece, resultando em erro.
	
	No interpretador, mudamos a implementação para que as funções fossem adicionadas no \textit{environment} simultaneamente. Assim, todas se enxergam mutuamente.
	
\subsection{Verificação de tipos}
Intuitivamente, acreditávamos no início do projeto que implementar uma linguagem tipada seria mais fácil do que uma não-tipada. Isso porque parece haver uma certa mágica por trás de algo do tipo
\begin{Verbatim}
x = 5; x = {1,2,3,2,1,5,2,2};
\end{Verbatim}

Porém, como a memória é abstraída pela \textit{Store}, os dois comandos acima são triviais. O valor que é armazenado na \textit{Store} pode ser inteiro ou vetor, e isto não faz diferença no interpretador.

\subsection{Implementação dos Algoritmos de Machine Learning}
A implementação dos algoritmos de Machine Learning resultou em mais de 1100 linhas de código.

\subsection{MLLex e MLYacc}
Sentimos falta de um bom tutorial para utilização destas ferramentas. Já tínhamos o CLex e o CYacc prontos desde a fase anterior e, mesmo assim, gastamos bastante tempo fazendo a tradução para MLLex e MLYacc.

\subsection{O nome da linguagem}
Achamos genial a ideia de chamar a linguagem de CML: é composta pelas iniciais de nossos nomes, pode ser interpretada como "C para Machine Learning", e parece com SML, a linguagem do interpretador.

Achamos menos genial esta ideia quando digitamos

\begin{Verbatim}
CML.make "CM.sml"
\end{Verbatim}

ao invés de
\begin{Verbatim}
CM.make "CML.cm"
\end{Verbatim}

\subsection{\textit{git}}
O \textit{git} foi uma dificuldade, pois dois integrantes do grupo não o conheciam muito bem. Ao mesmo tempo foi uma facilidade, pois tornou a manutenção e sincronização de código muito mais fácil, com criações de novas \textit{branches}, etc.

\subsection{\texttt{datatypes.sml}}
O CM e as bibliotecas de MLLex e MLYacc que usamos permitem que especifiquemos as estruturas que armazenam as \textit{parse trees}, tornando-as mais abstratas, sem a inclusão, por exemplo, de ";" nas expressões-comando.

\subsection{Conversão da semântica denotacional para SML}
Foi fácil. Praticamente uma cópia.

\subsection{CLex e CYacc}
O fato de termos feito os arquivos CLex e CYacc na fase anterior facilitou bastante a escrita do MLLex e MLYacc correspondentes.

\section{Curiosidades}
As funções predefinidas \texttt{print} e \texttt{println} que criamos são polimórficas, podendo receber valores de quaisquer tipos. Não seria difícil de implementarmos um tipo \texttt{any} na linguagem que define uma variável que pode assumir qualquer valor de qualquer tipo. Por exemplo, poderíamos ter um código como
\begin{Verbatim}
any x = 42; x = {1,2,3}; x = 5.2;
\end{Verbatim}

na nossa linguagem.
\section{Conclusão}
Durante esta disciplina, construímos uma linguagem para Machine Learning baseando-nos em C. Sofremos e aprendemos bastante. A nossa linguagem, embora, no estado atual, não seja uma boa opção comparada com linguagens como \textit{Python}, ela tem potencial. De fato, CML tem checagem de tipos, que evita códigos que especificam tipos de parâmetros em comentários em \textit{Python}. Além disso, é possível adicionar elementos sintáticos específicos para Machine Learning, algo que uma linguagem de propósito geral jamais teria.

\begin{thebibliography}{8}
\bibitem{Chap9}
  Slonneger, Kenneth and Kurtz, Barry L
  \textit{Formal syntax and semantics of programming languages},
  Addison-Wesley Reading
  1995
  Disponível em \url{http://www.divms.uiowa.edu/~slonnegr/plf/Book/Chapter9.pdf}

\item ANSI C Yacc Grammar - \url{http://www.quut.com/c/ANSI-C-grammar-y.html}

\item MLLex - gerador de analisadores léxicos -  \url{https://www.smlnj.org/doc/ML-Lex} 

\item MLYacc - gerador de analisadores sintáticos - \url{http://www.smlnj.org/doc/ML-Yacc/}

\item SML/NJ Compilation Manager - gerenciador de compilação para uso de MLLex e MLYacc - \url{https://www.smlnj.org/doc/CM/index.html}

\item User's guide to MLLex and MLYacc - guia de MLLex, MLYacc e SML/NJ Compilation Manager \url{www.cs.tufts.edu/comp/181/ug.pdf}

\item ANSI C Yacc grammar - gramática em Yacc e Lex para ANSI C - \url{http://www.quut.com/c/ANSI-C-grammar-y.html}

\item ANSI C Lex specification - especificação Lex para ANSI C - \url{http://www.quut.com/c/ANSI-C-grammar-l-2011.html}
\end{thebibliography}
	
\end{document}